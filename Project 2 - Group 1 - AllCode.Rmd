---
title: "DS 6030 Group 1"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---

```{r load-packages}
#| message: FALSE
#| warning: FALSE
rm(list=ls())
library(tidyverse)
library(tidymodels)
library(ggplot2)
library(dplyr)
library(future)
library(kknn)
library(discrim)
library(patchwork)
library(probably)
library(klaR)
library(yardstick)
knitr::opts_chunk$set(cache=TRUE, autodep=TRUE)
knitr::opts_chunk$set(echo=TRUE)
knitr::opts_chunk$set(fig.align="center", fig.pos="tbh")
```


```{r setup-parallel}
plan(multisession, workers = parallel::detectCores(logical = FALSE))
```

```{r}
haiti <- read.csv("https://gedeck.github.io/DS-6030/project/HaitiPixels.csv", header = TRUE)

head(haiti)

```

```{r}

#haiti  %>% 
#  group_by(Class) %>% 
#  summarize(RedMn = mean(Red), GreenMn = mean(Green), BlueMn = mean(Blue))

#names(haiti)

#Preprocess - classification is blue tarp/not blue tarp

train = haiti %>% 
  mutate(Class = factor(ifelse(Class != 'Blue Tarp', 'Not_Blue', 'Blue')))
         

levels(train$Class) <- c("Blue", "Not_Blue")
         

train  %>% 
  group_by(Class) %>% 
  summarize(RedMn = mean(Red), GreenMn = mean(Green), BlueMn = mean(Blue))


```

```{r}

resamples <- vfold_cv(train, v=10, strata=Class)
metrics <- metric_set(roc_auc, accuracy)
cv_control <- control_resamples(save_pred=TRUE)

formula <- Class ~ Red + Green + Blue

rec <- recipe(formula, data=train) %>%
  step_normalize(all_numeric_predictors())


logreg_spec <- logistic_reg(mode="classification", engine="glm")

logreg_wf <- workflow() %>%
 add_recipe(rec) %>%
 add_model(logreg_spec)

#logreg cv
logreg_cv <- fit_resamples(logreg_wf, resamples, metrics=metrics, control=cv_control)

```

```{r}

#logreg metrics
cv_metrics <- bind_rows(collect_metrics(logreg_cv) %>%
                          mutate(model="Logistic regression"))

cv_metrics 

```

```{r}
lda_spec <- discrim_linear(mode="classification", engine="MASS")

lda_wf <- workflow() %>%
 add_recipe(rec) %>%
 add_model(lda_spec)

#lda cv
lda_cv <- fit_resamples(lda_wf, resamples, metrics=metrics, control=cv_control)

```

```{r}

#lda metrics
cv_metrics <- bind_rows(collect_metrics(lda_cv) %>%
 mutate(model="LDA"))

cv_metrics 


```

```{r}
cv_metrics <- bind_rows(
 collect_metrics(logreg_cv) %>%
 mutate(model="Logistic regression"),
 collect_metrics(lda_cv) %>%
 mutate(model="LDA")
)

cv_metrics


ggplot(cv_metrics, aes(x=mean, y=model, xmin=mean - std_err, xmax=mean + std_err)) +
  geom_point() +
  geom_linerange() +
  facet_wrap(~ .metric)
```

```{r}
roc_cv_plot <- function(model_cv, model_name) {
cv_predictions <- collect_predictions(model_cv)
cv_roc <- cv_predictions %>% roc_curve(truth=Class, .pred_Blue, event_level="first")
autoplot(cv_roc) +
labs(title=model_name)
}
g1 <- roc_cv_plot(logreg_cv, "Logistic regression")
g2 <- roc_cv_plot(lda_cv, "LDA")
g1 + g2
```
```{r}
logreg_model <- logreg_wf %>% fit(train)
lda_model <- lda_wf %>% fit(train)
```


```{r}
#pull in holdout data

read_holdout <- function(filename, label) {
  df <- read.table(filename, header = FALSE, skip = 10)
  colnames(df) <- c("ID", "X", "Y", "MapX", "MapY", "Lat", "Lon", "B1", "B2", "B3")
  df$Class <- label
  return(df[, c("Class", "B1", "B2", "B3")])}
 
BT_078 <- read_holdout("orthovnir078_ROI_Blue_Tarps.txt", "Blue Tarp")
NBT_078 <- read_holdout("orthovnir078_ROI_NON_Blue_Tarps.txt", "Non-Blue Tarp")
 
BT_069 <- read_holdout("orthovnir069_ROI_Blue_Tarps.txt", "Blue Tarp")
NBT_069 <- read_holdout("orthovnir069_ROI_NOT_Blue_Tarps.txt", "Non-Blue Tarp")
 
BT_067 <- read_holdout("orthovnir067_ROI_Blue_Tarps.txt", "Blue Tarp")
NBT_067 <- read_holdout("orthovnir067_ROI_NOT_Blue_Tarps.txt", "Non-Blue Tarp")
 
NBT_057 <- read_holdout("orthovnir057_ROI_NON_Blue_Tarps.txt", "Non-Blue Tarp")

```


```{r}

#NBT_057 (only has No blue tarp)

BT_067$Class = "Blue"
BT_067$Class = as.factor(BT_067$Class)

BT_067 = BT_067 %>%
  dplyr::select(Class, B1, B2, B3) %>%
  rename('Red' = 'B1', 'Green' = 'B2', 'Blue' = 'B3')


NBT_067$Class = "Not_Blue"
NBT_067$Class = as.factor(NBT_067$Class)

NBT_067 = NBT_067 %>%
  dplyr::select(Class, B1, B2, B3) %>%
  rename('Red' = 'B1', 'Green' = 'B2', 'Blue' = 'B3')


test_067 = rbind(BT_067, NBT_067)

test_067$Class = as.factor(test_067$Class)
levels(test_067$Class) <- c("Blue", "Not_Blue")

test_067 = test_067 %>% drop_na()

###

BT_069$Class = "Blue"
BT_069$Class = as.factor(BT_069$Class)

BT_069 = BT_069 %>%
  dplyr::select(Class, B1, B2, B3) %>%
  rename('Red' = 'B1', 'Green' = 'B2', 'Blue' = 'B3')


NBT_069$Class = "Not_Blue"
NBT_069$Class = as.factor(NBT_069$Class)

NBT_069 = NBT_069 %>%
  dplyr::select(Class, B1, B2, B3) %>%
  rename('Red' = 'B1', 'Green' = 'B2', 'Blue' = 'B3')


test_069 = rbind(BT_069, NBT_069)

test_069$Class = as.factor(test_069$Class)
levels(test_069$Class) <- c("Blue", "Not_Blue")

test_069 = test_069 %>% drop_na()
###

BT_078$Class = "Blue"
BT_078$Class = as.factor(BT_078$Class)

BT_078 = BT_078 %>% 
  dplyr::select(Class, B1, B2, B3) %>% 
  rename('Red' = 'B1', 'Green' = 'B2', 'Blue' = 'B3')

NBT_078$Class = "Not_Blue"
NBT_078$Class = as.factor(NBT_078$Class)

NBT_078 = NBT_078 %>%
  dplyr::select(Class, B1, B2, B3) %>%
  rename('Red' = 'B1', 'Green' = 'B2', 'Blue' = 'B3')


test_078 = rbind(BT_078, NBT_078)

test_078$Class = as.factor(test_078$Class)
levels(test_078$Class) <- c("Blue", "Not_Blue")

test_078 = test_078 %>% drop_na() 
```

```{r}
holdout_067 <- bind_rows(roc_auc(augment(logreg_model, train), Class, .pred_Blue, event_level="first") %>%
                       mutate(model="logreg train"), 
                     roc_auc(augment(logreg_model, test_067), Class, .pred_Blue, event_level="first") %>%
                       mutate(model="logreg test 067"),
                     roc_auc(augment(logreg_model, test_067), Class, .pred_Blue, event_level="first") %>%
                       mutate(model="logreg test 069"),
                     roc_auc(augment(logreg_model, test_067), Class, .pred_Blue, event_level="first") %>%
                       mutate(model="logreg test 078"),
                     roc_auc(augment(lda_model, train), Class, .pred_Blue, event_level="first") %>%
                       mutate(model="LDA train"),
                     roc_auc(augment(lda_model, test_067), Class, .pred_Blue, event_level="first") %>%
                       mutate(model="LDA test 067"),
                     roc_auc(augment(lda_model, test_067), Class, .pred_Blue, event_level="first") %>%
                       mutate(model="LDA test 069"),
                     roc_auc(augment(lda_model, test_067), Class, .pred_Blue, event_level="first") %>%
                       mutate(model="LDA test 078"),
                     )


ggplot(holdout_067, aes(x=.estimate, y=model)) +
geom_point() +
facet_wrap(~ .metric)

```


```{r}
haiti <- read.csv("https://gedeck.github.io/DS-6030/project/HaitiPixels.csv", header = TRUE)

mean(haiti$Red, rm.na = T)

mean(haiti$Blue, rm.na = T)

mean(haiti$Green, rm.na = T)

```

```{r}
#Trying to determine which of B1, B2, B3 is Blue. When comparing blue tarp to non blue tarp files, A higher mean value of Bx should tell us which one is blue
df_blue <- read.table("orthovnir067_ROI_Blue_Tarps.txt", header = FALSE, skip = 10)
df_nonblue <- read.table("orthovnir067_ROI_NOT_Blue_Tarps.txt", header = FALSE, skip = 10)
colnames(df_blue) <- colnames(df_nonblue) <- c("ID", "X", "Y", "MapX", "MapY", "Lat", "Lon", "B1", "B2", "B3")

mean_blue <- colMeans(df_blue[, c("B1", "B2", "B3")])
mean_nonblue <- colMeans(df_nonblue[, c("B1", "B2", "B3")])


print("Blue Tarps - mean")
print(mean_blue)

print("Non-Blue Tarps - mean")
print(mean_nonblue)
```
B3 seems to be the obvious label for "Blue" with an average B3 of 176.85 compared to Non-Blue's 92.22

```{r}
#Now trying to confirm if B1 and B2 are red or green
#Trying to understand a baseline of the means using the training set. We assume green is more prevalent in "vegetation" and red is more prevalent in "soil"
training_mean <- haiti %>%
  filter(Class %in% c("Vegetation", "Soil")) %>%
  group_by(Class) %>%
  summarise(
    MeanRed = mean(Red),
    MeanGreen = mean(Green))
print(training_mean)
#Red appears to be brighter in both cases of soil and vegetation - meaning if B1 or B2 is brighter - that would be the 'red"


RGtest <- read.table("orthovnir067_ROI_NOT_Blue_Tarps.txt", header=FALSE, skip=10)
colnames(RGtest) <- c("ID", "X", "Y", "MapX", "MapY", "Lat", "Lon", "B1", "B2", "Blue")

holdout_means <- colMeans(RGtest[, c("B1", "B2")])
print(holdout_means)
```
B1 is brighter, meaning it should be "Red". B1 = Red, B2 = Green, B3 = Blue

```{r}
#Applying the same column headers to all holdout files
read_holdout<- function(filename, label) {
  df <- read.table(filename, header = FALSE, skip = 10)
  colnames(df) <- c("ID", "X", "Y", "MapX", "MapY", "Lat", "Lon", "Red", "Green", "Blue")
  df$Class <- label
  df[, c("Class", "Red", "Green", "Blue")]}

Blue078 <- read_holdout("orthovnir078_ROI_Blue_Tarps.txt", "Blue Tarp")
NonBlue078 <- read_holdout("orthovnir078_ROI_NON_Blue_Tarps.txt", "Non-Blue Tarp")

Blue069 <- read_holdout("orthovnir069_ROI_Blue_Tarps.txt", "Blue Tarp")
NonBlue069 <- read_holdout("orthovnir069_ROI_NOT_Blue_Tarps.txt", "Non-Blue Tarp")

Blue067 <- read_holdout("orthovnir067_ROI_Blue_Tarps.txt", "Blue Tarp")
NonBlue067 <- read_holdout("orthovnir067_ROI_NOT_Blue_Tarps.txt", "Non-Blue Tarp")

NonBlue057 <- read_holdout("orthovnir057_ROI_NON_Blue_Tarps.txt", "Non-Blue Tarp")
```

```{r}
#Combining all holdout files
holdout<- rbind(
  Blue078, NonBlue078,
  Blue069, NonBlue069,
  Blue067, NonBlue067,
  NonBlue057)
```

```{r}
#Holdout Data Class Breakdown
holdout%>%
  count(Class) %>%
  ggplot(aes(x = "", y = n, fill = Class)) +
  geom_col(width = 1, color = "white") +
  coord_polar(theta = "y") +
  ggtitle("Holdout Data: Class Distribution") +
  theme_void() +
  theme(legend.title = element_blank())+
  scale_fill_manual(values = c(
    "Blue Tarp" = "dodgerblue2",
    "Non-Blue Tarp" = "azure4"))

#Training Set Class Breakdown
haiti %>%
  count(Class) %>%
  ggplot(aes(x = "", y = n, fill = Class)) +
  geom_col(width = 1, color = "white") +
  coord_polar(theta = "y") +
  ggtitle("Training Data: Class Distribution") +
  theme_void() +
  theme(legend.title = element_blank())+
  scale_fill_manual(values = c(
    "Blue Tarp" = "dodgerblue2",
    "Vegetation" = "green4",
    "Soil" = "lightsalmon4",
    "Rooftop" = "firebrick3",
    "Various Non-Tarp" = "gold2"))
```

***QDA***

```{r}

# Training data (retain all original classes)
train_data <- haiti %>% 
  mutate(Class = factor(ifelse(Class != 'Blue Tarp', 'Not_Blue', 'Blue')))

```

```{r}

set.seed(123)
folds <- vfold_cv(train_data, v = 5)

```

```{r}
# QDA model
mymetrics <- metric_set(accuracy, roc_auc)
qda_spec <- discrim_quad() %>%
  set_mode("classification") %>%
  set_engine("MASS")

qda_wf <- workflow() %>%
  add_model(qda_spec) %>%
  add_formula(Class ~ Red + Green + Blue)

# Fit resamples with ROC AUC and accuracy
qda_res <- fit_resamples(
  qda_wf,
  resamples = folds,
  metrics = mymetrics,
  control = control_resamples(save_pred = TRUE)
)
```


```{r}

# Collect and print resample metrics
print(collect_metrics(qda_res))

# Fit final model on full training data
qda_fit <- qda_wf %>%
  fit(data = train_data)
```

```{r}

# QDA Holdout Data

test_data <- holdout %>% 
  mutate(Class = factor(ifelse(Class != 'Blue Tarp', 'Not_Blue', 'Blue')))

holdout_preds <- augment(qda_fit, new_data = test_data)

holdout_results <- bind_rows(
  roc_auc(holdout_preds, truth = Class, .pred_Blue, event_level = "first"),
  accuracy(holdout_preds, truth = Class, estimate = .pred_class),
  recall(holdout_preds, truth = Class, estimate = .pred_class, event_level = "first"),
  precision(holdout_preds, truth = Class, estimate = .pred_class, event_level = "first"),
  f_meas(holdout_preds, truth = Class, estimate = .pred_class, event_level = "first")) %>%
  mutate(result = "Holdout")


knitr::kable(holdout_results, caption = "Holdout Set Performance Metrics")




```

```{r}
# Holdout Confusion Matrix

holdout_preds %>% conf_mat(truth = Class, estimate = .pred_class) %>% autoplot(type = "heatmap")

```

```{r}

#ROC Curves for Training Data

# Filter prediction probability columns
pred_cols <- names(holdout_preds)[startsWith(names(holdout_preds), ".pred_")]
pred_cols <- setdiff(pred_cols, ".pred_class")

qda_roc_long <- holdout_preds %>%
  dplyr::select(Class, all_of(pred_cols)) %>%
  tidyr::pivot_longer(
    cols = all_of(pred_cols),
    names_to = "Class_label",
    names_prefix = ".pred_",
    values_to = "prob"
  ) %>%
  mutate(Class_label = factor(Class_label, levels = levels(holdout_preds$Class)))

# Function to create ROC curve for one class (one-vs-all)
roc_one_vs_all <- function(data, class_name) {
  data %>%
    mutate(
      binary_truth = factor(
        ifelse(Class == class_name, class_name, paste0("Not_", class_name)),
        levels = c(class_name, paste0("Not_", class_name))
      )
    ) %>%
    
    filter(Class_label == class_name) %>%
    roc_curve(binary_truth, prob) %>%
    mutate(class = class_name)
}


# Get ROC curves for each class separately and combine
roc_data <- purrr::map_dfr(levels(holdout_preds$Class), ~ roc_one_vs_all(qda_roc_long, .x))

# Plot all ROC curves
ggplot(roc_data, aes(x = 1 - specificity, y = sensitivity, color = class)) +
  geom_line(linewidth = 1) +
  geom_abline(linetype = "dashed") +
  labs(title = "One-vs-All ROC Curves for Multiclass QDA (Training Set)",
       x = "False Positive Rate (1 - Specificity)",
       y = "True Positive Rate (Sensitivity)",
       color = "Class") +
  theme_minimal()
```

Sources:

Roever, Christian, et al. Package “KlaR” Title Classification and Visualization. 2018.

***SVM***
```{r}
library(LiblineaR)
```

```{r}
haiti_binary <- haiti %>%
  mutate(Class = if_else(Class == "Blue Tarp", "Blue Tarp", "Non-Blue Tarp")) %>%
  mutate(Class = factor(Class, levels = c("Non-Blue Tarp", "Blue Tarp")))


holdout_binary <- holdout %>%
  mutate(Class = factor(Class, levels = c("Non-Blue Tarp", "Blue Tarp")))
```

```{r}
#Recipe: normalizing predictors (Red, Green, Blue)
svm_recipe <- recipe(Class ~ Red + Green + Blue, data = haiti_binary) %>%
  step_normalize(all_predictors())

#Linear SVM with default cost and margin
svm_spec <- svm_linear(mode = "classification") %>%
  set_engine("kernlab")

#Workflow
svm_wf <- workflow() %>%
  add_model(svm_spec) %>%
  add_recipe(svm_recipe)
```

```{r}
#Cross-validation setup with stratification
set.seed(123)
folds <- vfold_cv(haiti_binary, v = 5, strata = Class)

#Fitting the model with resamples and collecting metrics
svm_fit <- fit_resamples(
  svm_wf,
  resamples = folds,
  metrics = metric_set(accuracy, precision, recall, f_meas, roc_auc),
  control = control_resamples(save_pred = TRUE))
```

```{r}
#Performance summary
collect_metrics(svm_fit)

svm_fit %>%
  collect_predictions() %>%
  roc_curve(Class, `.pred_Blue Tarp`, event_level="second") %>%
  autoplot()

```

```{r}
final_svm_fit <- fit(svm_wf, data = haiti_binary)
holdout_preds <- predict(final_svm_fit, new_data = holdout_binary, type = "prob") %>%
  bind_cols(predict(final_svm_fit, new_data = holdout_binary)) %>%
  bind_cols(holdout_binary %>% dplyr::select(Class))

holdout_results <- bind_rows(
  roc_auc(holdout_preds, truth = Class, `.pred_Blue Tarp`, event_level = "second"),
  accuracy(holdout_preds, truth = Class, estimate = .pred_class),
  recall(holdout_preds, truth = Class, estimate = .pred_class, event_level = "first"),
  precision(holdout_preds, truth = Class, estimate = .pred_class, event_level = "first"),
  f_meas(holdout_preds, truth = Class, estimate = .pred_class, event_level = "first")) %>%
  mutate(result = "Holdout")


knitr::kable(holdout_results, caption = "Holdout Set Performance Metrics")

holdout_preds %>%
  conf_mat(truth = Class, estimate = .pred_class)

holdout_preds %>%
  roc_curve(truth = Class, `.pred_Blue Tarp`, event_level="second") %>%
  autoplot()
```

***KNN***
```{r, warning=FALSE}
# perform pre-processing of data to convert class to factor, rest as integers
haiti$Class <- as.factor(haiti$Class)
holdout$Class <- as.factor(holdout$Class)

# ensure same classes exist across training and test/holdout data
haiti$Class <- ifelse(haiti$Class == "Blue Tarp",
                      "Blue Tarp",
                      "Non-Blue Tarp")
haiti$Class <- as.factor(haiti$Class)

haiti %>%
  count(Class) %>%
  ggplot(aes(x = "", y = n, fill = Class)) +
  geom_col(width = 1, color = "white") +
  coord_polar(theta = "y") +
  ggtitle("Training Data: Class Distribution (after reclassifying)") +
  theme_void() +
  theme(legend.title = element_blank())+
  scale_fill_manual(values = c(
    "Blue Tarp" = "dodgerblue2",
    "Non-Blue Tarp" = "azure4"))
```

```{r, warning=FALSE}
set.seed(123)
resamples <- vfold_cv(haiti, v=10, strata=Class)
cv_metrics <- metric_set(roc_auc, accuracy, f_meas, precision, recall)
cv_control <- control_resamples(save_pred=TRUE)
```

```{r, warning=FALSE}
formula <- Class ~ Red + Green + Blue
knn_rec <- recipe(formula, data=haiti) %>% 
  step_normalize(all_numeric_predictors())
knn_model <- nearest_neighbor(mode="classification", neighbors=tune()) %>% 
  set_engine("kknn")

knn_wf <- workflow() %>%
  add_model(knn_model) %>% 
  add_recipe(knn_rec)
  
parameters <- extract_parameter_set_dials(knn_wf) %>% 
  update(neighbors = neighbors(c(1, 50)))

tune_knn_wf <- tune_grid(knn_wf,
                          resamples=resamples,
                          grid=grid_regular(parameters, levels=10))
```

```{r, warning=FALSE}
autoplot(tune_knn_wf)
```

```{r, warning=FALSE}
best_parameter <- select_best(tune_knn_wf, metric = "accuracy")

best_knn_wf <- knn_wf %>%
  finalize_workflow(best_parameter)

result_cv <- fit_resamples(best_knn_wf, resamples, metrics = cv_metrics, control = cv_control)

final_fitted_knn_model <- best_knn_wf %>% 
  fit(haiti)

cv_results <- collect_metrics(result_cv) %>%
  mutate(result = "Cross-Validation")

cv_results
```

```{r, warning=FALSE}
holdout_preds <- augment(final_fitted_knn_model, new_data=holdout)
training_preds <- augment(final_fitted_knn_model, new_data=haiti)

training_results <- bind_rows(
  roc_auc(training_preds, truth = Class, `.pred_Blue Tarp`, event_level = "first"),
  accuracy(training_preds, truth = Class, estimate = .pred_class),
  recall(training_preds, truth = Class, estimate = .pred_class, event_level = "first"),
  precision(training_preds, truth = Class, estimate = .pred_class, event_level = "first"),
  f_meas(training_preds, truth = Class, estimate = .pred_class, event_level = "first")) %>%
  dplyr::select(-.estimator) %>%
  mutate(result = "Training")

holdout_results <- bind_rows(
  roc_auc(holdout_preds, truth = Class, `.pred_Blue Tarp`, event_level = "first"),
  accuracy(holdout_preds, truth = Class, estimate = .pred_class),
  recall(holdout_preds, truth = Class, estimate = .pred_class, event_level = "first"),
  precision(holdout_preds, truth = Class, estimate = .pred_class, event_level = "first"),
  f_meas(holdout_preds, truth = Class, estimate = .pred_class, event_level = "first")) %>%
  dplyr::select(-.estimator) %>%
  mutate(result = "Holdout")

knitr::kable(training_results, caption = "Training Set Performance Metrics")

knitr::kable(holdout_results, caption = "Holdout Set Performance Metrics")
```

```{r, warning=FALSE}
roc_data <- roc_curve(holdout_preds, truth = Class, `.pred_Blue Tarp`, event_level = "first")
autoplot(roc_data) +
  labs(title="KNN ROC Curve")
```
