---
title: "DS 6030 Group 1"
date: "`r Sys.Date()`"
output:
  html_document: default
---

```{r load-packages}
#| message: FALSE
#| warning: FALSE
rm(list=ls())
library(tidyverse)
library(tidymodels)
library(ggplot2)
library(dplyr)
library(future)
library(kknn)
library(discrim)
library(patchwork)
library(probably)
library(klaR)
library(yardstick)
knitr::opts_chunk$set(cache=TRUE, autodep=TRUE)
knitr::opts_chunk$set(echo=TRUE)
knitr::opts_chunk$set(fig.align="center", fig.pos="tbh")
```


```{r setup-parallel}
plan(multisession, workers = parallel::detectCores(logical = FALSE))
```

```{r}
haiti <- read.csv("https://gedeck.github.io/DS-6030/project/HaitiPixels.csv", header = TRUE)

head(haiti)

```

```{r}

#haiti  %>% 
#  group_by(Class) %>% 
#  summarize(RedMn = mean(Red), GreenMn = mean(Green), BlueMn = mean(Blue))

#names(haiti)

#Preprocess - classification is blue tarp/not blue tarp

train = haiti %>% 
  mutate(Class = factor(ifelse(Class != 'Blue Tarp', 'Not_Blue', 'Blue')))
         

levels(train$Class) <- c("Blue", "Not_Blue")
         

train  %>% 
  group_by(Class) %>% 
  summarize(RedMn = mean(Red), GreenMn = mean(Green), BlueMn = mean(Blue))


```

```{r}
#Applying the same column headers to all holdout files
read_holdout<- function(filename, label) {
  df <- read.table(filename, header = FALSE, skip = 10)
  colnames(df) <- c("ID", "X", "Y", "MapX", "MapY", "Lat", "Lon", "Red", "Green", "Blue")
  df$Class <- label
  df[, c("Class", "Red", "Green", "Blue")]}

Blue078 <- read_holdout("orthovnir078_ROI_Blue_Tarps.txt", "Blue Tarp")
NonBlue078 <- read_holdout("orthovnir078_ROI_NON_Blue_Tarps.txt", "Non-Blue Tarp")

Blue069 <- read_holdout("orthovnir069_ROI_Blue_Tarps.txt", "Blue Tarp")
NonBlue069 <- read_holdout("orthovnir069_ROI_NOT_Blue_Tarps.txt", "Non-Blue Tarp")

Blue067 <- read_holdout("orthovnir067_ROI_Blue_Tarps.txt", "Blue Tarp")
NonBlue067 <- read_holdout("orthovnir067_ROI_NOT_Blue_Tarps.txt", "Non-Blue Tarp")

NonBlue057 <- read_holdout("orthovnir057_ROI_NON_Blue_Tarps.txt", "Non-Blue Tarp")
```

```{r}
#Combining all holdout files
holdout<- rbind(
  Blue078, NonBlue078,
  Blue069, NonBlue069,
  Blue067, NonBlue067,
  NonBlue057)
```

***Logistic Regression***
```{r, warning=FALSE}
# perform pre-processing of data to convert class to factor, rest as integers
haiti$Class <- as.factor(haiti$Class)
holdout$Class <- as.factor(holdout$Class)

# ensure same classes exist across training and test/holdout data
haiti$Class <- ifelse(haiti$Class == "Blue Tarp",
                      "Blue Tarp",
                      "Non-Blue Tarp")
haiti$Class <- as.factor(haiti$Class)

```

```{r, warning=FALSE}
set.seed(123)
resamples <- vfold_cv(haiti, v=10, strata=Class)
cv_metrics <- metric_set(roc_auc, accuracy, f_meas, precision, recall)
cv_control <- control_resamples(save_pred=TRUE)
```

```{r, warning=FALSE}
formula <- Class ~ Red + Green + Blue
log_rec <- recipe(formula, data=haiti) %>% 
  step_normalize(all_numeric_predictors())

logreg_model <- logistic_reg(mode="classification", engine="glm")

logreg_wf <- workflow() %>%
  add_model(logreg_model) %>% 
  add_recipe(log_rec)

result_cv <- fit_resamples(logreg_wf, resamples, metrics = cv_metrics, control = cv_control)

final_logreg_model <- logreg_wf %>% 
  fit(haiti)

cv_results <- collect_metrics(result_cv) %>%
  mutate(result = "Cross-Validation")

cv_results
```

```{r, warning=FALSE}
holdout_preds <- augment(final_logreg_model, new_data=holdout)
training_preds <- augment(final_logreg_model, new_data=haiti)

training_results <- bind_rows(
  roc_auc(training_preds, truth = Class, `.pred_Blue Tarp`, event_level = "first"),
  accuracy(training_preds, truth = Class, estimate = .pred_class),
  recall(training_preds, truth = Class, estimate = .pred_class, event_level = "first"),
  precision(training_preds, truth = Class, estimate = .pred_class, event_level = "first"),
  f_meas(training_preds, truth = Class, estimate = .pred_class, event_level = "first")) %>%
  dplyr::select(-.estimator) %>%
  mutate(result = "Training")

holdout_results <- bind_rows(
  roc_auc(holdout_preds, truth = Class, `.pred_Blue Tarp`, event_level = "first"),
  accuracy(holdout_preds, truth = Class, estimate = .pred_class),
  recall(holdout_preds, truth = Class, estimate = .pred_class, event_level = "first"),
  precision(holdout_preds, truth = Class, estimate = .pred_class, event_level = "first"),
  f_meas(holdout_preds, truth = Class, estimate = .pred_class, event_level = "first")) %>%
  dplyr::select(-.estimator) %>%
  mutate(result = "Holdout")

knitr::kable(training_results, caption = "Training Set Performance Metrics")

knitr::kable(holdout_results, caption = "Holdout Set Performance Metrics")


holdout_preds %>% conf_mat(truth = Class, estimate = .pred_class) %>% autoplot(type = "heatmap")
```

```{r, warning=FALSE}
roc_data <- roc_curve(holdout_preds, truth = Class, `.pred_Blue Tarp`, event_level = "first")
autoplot(roc_data) +
  labs(title="Logistic Regression ROC Curve")
```

***Linear Discriminant Analysis (LDA)***
```{r, warning=FALSE}
lda_rec <- recipe(formula, data=haiti) %>% 
  step_normalize(all_numeric_predictors())

lda_model <- discrim_linear(mode="classification", engine="MASS")

lda_wf <- workflow() %>%
  add_model(lda_model) %>% 
  add_recipe(lda_rec)

result_cv <- fit_resamples(lda_wf, resamples, metrics = cv_metrics, control = cv_control)

final_lda_model <- lda_wf %>% 
  fit(haiti)

cv_results <- collect_metrics(result_cv) %>%
  mutate(result = "Cross-Validation")

cv_results
```

```{r, warning=FALSE}
holdout_preds <- augment(final_lda_model, new_data=holdout)
training_preds <- augment(final_lda_model, new_data=haiti)

training_results <- bind_rows(
  roc_auc(training_preds, truth = Class, `.pred_Blue Tarp`, event_level = "first"),
  accuracy(training_preds, truth = Class, estimate = .pred_class),
  recall(training_preds, truth = Class, estimate = .pred_class, event_level = "first"),
  precision(training_preds, truth = Class, estimate = .pred_class, event_level = "first"),
  f_meas(training_preds, truth = Class, estimate = .pred_class, event_level = "first")) %>%
  dplyr::select(-.estimator) %>%
  mutate(result = "Training")

holdout_results <- bind_rows(
  roc_auc(holdout_preds, truth = Class, `.pred_Blue Tarp`, event_level = "first"),
  accuracy(holdout_preds, truth = Class, estimate = .pred_class),
  recall(holdout_preds, truth = Class, estimate = .pred_class, event_level = "first"),
  precision(holdout_preds, truth = Class, estimate = .pred_class, event_level = "first"),
  f_meas(holdout_preds, truth = Class, estimate = .pred_class, event_level = "first")) %>%
  dplyr::select(-.estimator) %>%
  mutate(result = "Holdout")

knitr::kable(training_results, caption = "Training Set Performance Metrics")

knitr::kable(holdout_results, caption = "Holdout Set Performance Metrics")


holdout_preds %>% conf_mat(truth = Class, estimate = .pred_class) %>% autoplot(type = "heatmap")
```

```{r, warning=FALSE}
roc_data <- roc_curve(holdout_preds, truth = Class, `.pred_Blue Tarp`, event_level = "first")
autoplot(roc_data) +
  labs(title="LDA ROC Curve")
```

```{r}
haiti <- read.csv("https://gedeck.github.io/DS-6030/project/HaitiPixels.csv", header = TRUE)

mean(haiti$Red, rm.na = T)

mean(haiti$Blue, rm.na = T)

mean(haiti$Green, rm.na = T)

```

```{r}
#Trying to determine which of B1, B2, B3 is Blue. When comparing blue tarp to non blue tarp files, A higher mean value of Bx should tell us which one is blue
df_blue <- read.table("orthovnir067_ROI_Blue_Tarps.txt", header = FALSE, skip = 10)
df_nonblue <- read.table("orthovnir067_ROI_NOT_Blue_Tarps.txt", header = FALSE, skip = 10)
colnames(df_blue) <- colnames(df_nonblue) <- c("ID", "X", "Y", "MapX", "MapY", "Lat", "Lon", "B1", "B2", "B3")

mean_blue <- colMeans(df_blue[, c("B1", "B2", "B3")])
mean_nonblue <- colMeans(df_nonblue[, c("B1", "B2", "B3")])


print("Blue Tarps - mean")
print(mean_blue)

print("Non-Blue Tarps - mean")
print(mean_nonblue)
```
B3 seems to be the obvious label for "Blue" with an average B3 of 176.85 compared to Non-Blue's 92.22

```{r}
#Now trying to confirm if B1 and B2 are red or green
#Trying to understand a baseline of the means using the training set. We assume green is more prevalent in "vegetation" and red is more prevalent in "soil"
training_mean <- haiti %>%
  filter(Class %in% c("Vegetation", "Soil")) %>%
  group_by(Class) %>%
  summarise(
    MeanRed = mean(Red),
    MeanGreen = mean(Green))
print(training_mean)
#Red appears to be brighter in both cases of soil and vegetation - meaning if B1 or B2 is brighter - that would be the 'red"


RGtest <- read.table("orthovnir067_ROI_NOT_Blue_Tarps.txt", header=FALSE, skip=10)
colnames(RGtest) <- c("ID", "X", "Y", "MapX", "MapY", "Lat", "Lon", "B1", "B2", "Blue")

holdout_means <- colMeans(RGtest[, c("B1", "B2")])
print(holdout_means)
```
B1 is brighter, meaning it should be "Red". B1 = Red, B2 = Green, B3 = Blue

```{r}
#Applying the same column headers to all holdout files
read_holdout<- function(filename, label) {
  df <- read.table(filename, header = FALSE, skip = 10)
  colnames(df) <- c("ID", "X", "Y", "MapX", "MapY", "Lat", "Lon", "Red", "Green", "Blue")
  df$Class <- label
  df[, c("Class", "Red", "Green", "Blue")]}

Blue078 <- read_holdout("orthovnir078_ROI_Blue_Tarps.txt", "Blue Tarp")
NonBlue078 <- read_holdout("orthovnir078_ROI_NON_Blue_Tarps.txt", "Non-Blue Tarp")

Blue069 <- read_holdout("orthovnir069_ROI_Blue_Tarps.txt", "Blue Tarp")
NonBlue069 <- read_holdout("orthovnir069_ROI_NOT_Blue_Tarps.txt", "Non-Blue Tarp")

Blue067 <- read_holdout("orthovnir067_ROI_Blue_Tarps.txt", "Blue Tarp")
NonBlue067 <- read_holdout("orthovnir067_ROI_NOT_Blue_Tarps.txt", "Non-Blue Tarp")

NonBlue057 <- read_holdout("orthovnir057_ROI_NON_Blue_Tarps.txt", "Non-Blue Tarp")
```

```{r}
#Combining all holdout files
holdout<- rbind(
  Blue078, NonBlue078,
  Blue069, NonBlue069,
  Blue067, NonBlue067,
  NonBlue057)
```

```{r}
#Holdout Data Class Breakdown
holdout%>%
  count(Class) %>%
  ggplot(aes(x = "", y = n, fill = Class)) +
  geom_col(width = 1, color = "white") +
  coord_polar(theta = "y") +
  ggtitle("Holdout Data: Class Distribution") +
  theme_void() +
  theme(legend.title = element_blank())+
  scale_fill_manual(values = c(
    "Blue Tarp" = "dodgerblue2",
    "Non-Blue Tarp" = "azure4"))

#Training Set Class Breakdown
haiti %>%
  count(Class) %>%
  ggplot(aes(x = "", y = n, fill = Class)) +
  geom_col(width = 1, color = "white") +
  coord_polar(theta = "y") +
  ggtitle("Training Data: Class Distribution") +
  theme_void() +
  theme(legend.title = element_blank())+
  scale_fill_manual(values = c(
    "Blue Tarp" = "dodgerblue2",
    "Vegetation" = "green4",
    "Soil" = "lightsalmon4",
    "Rooftop" = "firebrick3",
    "Various Non-Tarp" = "gold2"))
```
***QDA***

```{r}

# Training data (retain all original classes)
train_data_binary <- haiti %>%
  mutate(Class = ifelse(Class == "Blue Tarp", "Blue Tarp", "Non-Blue Tarp")) %>%
  mutate(Class = factor(Class, levels = c("Non-Blue Tarp", "Blue Tarp"))) %>%
  dplyr::select(Red, Green, Blue, Class)

```

```{r}

set.seed(123)
folds <- vfold_cv(train_data_binary, v = 5)

```

```{r}
# QDA model

qda_spec <- discrim_quad() %>%
  set_mode("classification") %>%
  set_engine("MASS")

qda_wf <- workflow() %>%
  add_model(qda_spec) %>%
  add_formula(Class ~ Red + Green + Blue)

qda_res <- fit_resamples(
  qda_wf,
  resamples = folds,
  metrics = metric_set(accuracy, roc_auc),
  control = control_resamples(save_pred = TRUE)
)
```


```{r}

# Collect and print resample metrics
print(collect_metrics(qda_res))

# Fit final model on full training data
qda_fit <- qda_wf %>% fit(data = train_data_binary)
```

```{r}

# QDA Holdout Data

test_data_binary <- holdout %>%
  mutate(Class = factor(Class, levels = c("Non-Blue Tarp", "Blue Tarp"))) %>%
  dplyr::select(Red, Green, Blue, Class)

holdout_preds <- augment(qda_fit, new_data = test_data_binary)


```

```{r}
# Accuracy & AUC on Holdout

metrics(holdout_preds, truth = Class, estimate = .pred_class)



```

```{r}

#ROC Curves for Holdout Data

roc_curve(holdout_preds, truth = Class, `.pred_Non-Blue Tarp`) %>%
  ggplot(aes(x = 1 - specificity, y = sensitivity)) +
  geom_line(color = "dodgerblue", linewidth = 1.2) +
  geom_abline(linetype = "dashed") +
  labs(title = "ROC Curve: Blue Tarp vs Non-Blue Tarp (Holdout Set)",
       x = "False Positive Rate (1 - Specificity)",
       y = "True Positive Rate (Sensitivity)") +
  theme_minimal()



# metrics table

qda_metrics <- bind_rows(
  accuracy(holdout_preds, truth = Class, estimate = .pred_class),
  recall(holdout_preds, truth = Class, estimate = .pred_class, event_level = "second"),
  precision(holdout_preds, truth = Class, estimate = .pred_class, event_level = "second"),
  f_meas(holdout_preds, truth = Class, estimate = .pred_class, event_level = "second"),
  roc_auc(holdout_preds, truth = Class, `.pred_Blue Tarp`, event_level = "second")
)

qda_metrics

# Confusion matrix as a data frame
conf_mat_tbl <- holdout_preds %>%
  conf_mat(truth = Class, estimate = .pred_class)

# Convert to a matrix
conf_mat_matrix <- as.matrix(conf_mat_tbl$table)

conf_mat_matrix
```

Sources:

Roever, Christian, et al. Package “KlaR” Title Classification and Visualization. 2018.

***SVM***
```{r}
library(LiblineaR)
```

```{r}
haiti_binary <- haiti %>%
  mutate(Class = if_else(Class == "Blue Tarp", "Blue Tarp", "Non-Blue Tarp")) %>%
  mutate(Class = factor(Class, levels = c("Non-Blue Tarp", "Blue Tarp")))


holdout_binary <- holdout %>%
  mutate(Class = factor(Class, levels = c("Non-Blue Tarp", "Blue Tarp")))
```

```{r}
#Recipe: normalizing predictors (Red, Green, Blue)
svm_recipe <- recipe(Class ~ Red + Green + Blue, data = haiti_binary) %>%
  step_normalize(all_predictors())

#Linear SVM with default cost and margin
svm_spec <- svm_linear(mode = "classification") %>%
  set_engine("kernlab")

#Workflow
svm_wf <- workflow() %>%
  add_model(svm_spec) %>%
  add_recipe(svm_recipe)
```

```{r}
#Cross-validation setup with stratification
set.seed(123)
folds <- vfold_cv(haiti_binary, v = 5, strata = Class)

#Fitting the model with resamples and collecting metrics
svm_fit <- fit_resamples(
  svm_wf,
  resamples = folds,
  metrics = metric_set(accuracy, precision, recall, f_meas, roc_auc),
  control = control_resamples(save_pred = TRUE))
```

```{r}
#Performance summary
collect_metrics(svm_fit)

svm_fit %>%
  collect_predictions() %>%
  roc_curve(Class, `.pred_Blue Tarp`, event_level="second") %>%
  autoplot()

```

```{r}
final_svm_fit <- fit(svm_wf, data = haiti_binary)
holdout_preds <- predict(final_svm_fit, new_data = holdout_binary, type = "prob") %>%
  bind_cols(predict(final_svm_fit, new_data = holdout_binary)) %>%
  bind_cols(holdout_binary %>% dplyr::select(Class))

holdout_results <- bind_rows(
  roc_auc(holdout_preds, truth = Class, `.pred_Blue Tarp`, event_level = "second"),
  accuracy(holdout_preds, truth = Class, estimate = .pred_class),
  recall(holdout_preds, truth = Class, estimate = .pred_class, event_level = "first"),
  precision(holdout_preds, truth = Class, estimate = .pred_class, event_level = "first"),
  f_meas(holdout_preds, truth = Class, estimate = .pred_class, event_level = "first")) %>%
  mutate(result = "Holdout")


knitr::kable(holdout_results, caption = "Holdout Set Performance Metrics")

holdout_preds %>%
  conf_mat(truth = Class, estimate = .pred_class)

holdout_preds %>%
  roc_curve(truth = Class, `.pred_Blue Tarp`, event_level="second") %>%
  autoplot()
```

***KNN***
```{r, warning=FALSE}
# perform pre-processing of data to convert class to factor, rest as integers
haiti$Class <- as.factor(haiti$Class)
holdout$Class <- as.factor(holdout$Class)

# ensure same classes exist across training and test/holdout data
haiti$Class <- ifelse(haiti$Class == "Blue Tarp",
                      "Blue Tarp",
                      "Non-Blue Tarp")
haiti$Class <- as.factor(haiti$Class)

haiti %>%
  count(Class) %>%
  ggplot(aes(x = "", y = n, fill = Class)) +
  geom_col(width = 1, color = "white") +
  coord_polar(theta = "y") +
  ggtitle("Training Data: Class Distribution (after reclassifying)") +
  theme_void() +
  theme(legend.title = element_blank())+
  scale_fill_manual(values = c(
    "Blue Tarp" = "dodgerblue2",
    "Non-Blue Tarp" = "azure4"))
```

```{r, warning=FALSE}
set.seed(123)
resamples <- vfold_cv(haiti, v=10, strata=Class)
cv_metrics <- metric_set(roc_auc, accuracy, f_meas, precision, recall)
cv_control <- control_resamples(save_pred=TRUE)
```

```{r, warning=FALSE}
formula <- Class ~ Red + Green + Blue
knn_rec <- recipe(formula, data=haiti) %>% 
  step_normalize(all_numeric_predictors())
knn_model <- nearest_neighbor(mode="classification", neighbors=tune()) %>% 
  set_engine("kknn")

knn_wf <- workflow() %>%
  add_model(knn_model) %>% 
  add_recipe(knn_rec)
  
parameters <- extract_parameter_set_dials(knn_wf) %>% 
  update(neighbors = neighbors(c(1, 50)))

tune_knn_wf <- tune_grid(knn_wf,
                          resamples=resamples, metrics = metric_set(accuracy, roc_auc, f_meas),
                          grid=grid_regular(parameters, levels=10))
```

```{r, warning=FALSE}
autoplot(tune_knn_wf)
```

```{r, warning=FALSE}
best_parameter <- select_best(tune_knn_wf, metric = "f_meas")

best_knn_wf <- knn_wf %>%
  finalize_workflow(best_parameter)

result_cv <- fit_resamples(best_knn_wf, resamples, metrics = cv_metrics, control = cv_control)

final_fitted_knn_model <- best_knn_wf %>% 
  fit(haiti)

cv_results <- collect_metrics(result_cv) %>%
  mutate(result = "Cross-Validation")

cv_results
```

```{r, warning=FALSE}
holdout_preds <- augment(final_fitted_knn_model, new_data=holdout)
training_preds <- augment(final_fitted_knn_model, new_data=haiti)

training_results <- bind_rows(
  roc_auc(training_preds, truth = Class, `.pred_Blue Tarp`, event_level = "first"),
  accuracy(training_preds, truth = Class, estimate = .pred_class),
  recall(training_preds, truth = Class, estimate = .pred_class, event_level = "first"),
  precision(training_preds, truth = Class, estimate = .pred_class, event_level = "first"),
  f_meas(training_preds, truth = Class, estimate = .pred_class, event_level = "first")) %>%
  dplyr::select(-.estimator) %>%
  mutate(result = "Training")

holdout_results <- bind_rows(
  roc_auc(holdout_preds, truth = Class, `.pred_Blue Tarp`, event_level = "first"),
  accuracy(holdout_preds, truth = Class, estimate = .pred_class),
  recall(holdout_preds, truth = Class, estimate = .pred_class, event_level = "first"),
  precision(holdout_preds, truth = Class, estimate = .pred_class, event_level = "first"),
  f_meas(holdout_preds, truth = Class, estimate = .pred_class, event_level = "first")) %>%
  dplyr::select(-.estimator) %>%
  mutate(result = "Holdout")

knitr::kable(training_results, caption = "Training Set Performance Metrics")

knitr::kable(holdout_results, caption = "Holdout Set Performance Metrics")


holdout_preds %>% conf_mat(truth = Class, estimate = .pred_class) %>% autoplot(type = "heatmap")
```

```{r, warning=FALSE}
roc_data <- roc_curve(holdout_preds, truth = Class, `.pred_Blue Tarp`, event_level = "first")
autoplot(roc_data) +
  labs(title="KNN ROC Curve")
```

```{r, warning=FALSE}
performance <- probably::threshold_perf(
  result_cv %>% collect_predictions(),
  Class, `.pred_Blue Tarp`, 
  seq(0.1, 0.9, 0.01), 
  event_level = "first",
  metrics = metric_set(j_index, f_meas, kap)
)

max_values <- performance %>%
  group_by(.metric) %>%
  filter(.estimate == max(.estimate)) %>%
  slice(1)

threshold <- max_values %>%
  filter(.metric == "f_meas") %>%
  pull(.threshold)

training_preds %>%
  mutate(.pred_class = factor(
      ifelse(`.pred_Blue Tarp` >= threshold, "Blue Tarp", "Non-Blue Tarp"),
      levels = c("Blue Tarp", "Non-Blue Tarp")))

threshold_training_results <- training_preds %>%
  f_meas(Class, .pred_class) %>%
  dplyr::select(-.estimator) %>%
  mutate(result = "Cross-validation", threshold = threshold)

holdout_predictions <- augment(final_fitted_knn_model, new_data=holdout) %>%
    mutate(.pred_class = factor(ifelse(`.pred_Blue Tarp` >= threshold, "Blue Tarp", "Non-Blue Tarp")))
holdout_threshold_results <-  bind_rows(
        c(f_meas(holdout_predictions, Class, .pred_class))
    ) %>%
    dplyr::select(-.estimator) %>%
    mutate(result="Holdout", threshold=threshold)

threshold_training_results
holdout_threshold_results
```
